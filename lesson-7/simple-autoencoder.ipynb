{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple autoencoder in PyTorch\n",
    "\n",
    "**[Faisal Z. Qureshi](http://vclab.science.uoit.ca)**  \n",
    "\n",
    "Check out excellent PyTorch tutorials by \"SherlockLiao\" at [https://github.com/L1aoXingyu/pytorch-beginner](https://github.com/L1aoXingyu/pytorch-beginner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: 0 - GeForce GTX TITAN X\n",
      "Found device: 1 - GeForce GTX 980\n",
      "Current cuda device is GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"Found device: {} - {}\".format(i,torch.cuda.get_device_name(i)))\n",
    "\n",
    "if torch.cuda.device_count() == 0:\n",
    "    print(\"No GPU device found\")\n",
    "else:\n",
    "    print(\"Current cuda device is\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper code that would allow us to use gpu and cpu seemlessly, I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cudafy:\n",
    "    \n",
    "    def __init__(self, device=None):\n",
    "        if torch.cuda.is_available() and device:\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = 0\n",
    "    \n",
    "    def name(self):\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.cuda.get_device_name(self.device)\n",
    "        return 'Cuda is not available.'\n",
    "    \n",
    "    def put(self, x):\n",
    "        \"\"\"Put x on the default cuda device.\"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            return x.to(device=self.device)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.put(x)\n",
    "    \n",
    "    def get(self,x):\n",
    "        \"\"\"Get from cpu.\"\"\"\n",
    "        if x.is_cuda:\n",
    "            return x.to(device='cpu')\n",
    "        return x\n",
    "    \n",
    "def cpu(x):\n",
    "    if x.is_cuda:\n",
    "        return x.to(device='cpu')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX TITAN X\n",
      "x is not on cuda False\n",
      "y is on cuda (if possible) True\n",
      "z is taken from y, z is not on cuda False\n",
      "w is taken from x, w is not on cuda False\n"
     ]
    }
   ],
   "source": [
    "gpu = cudafy()\n",
    "x = torch.ones((3,2))\n",
    "y = gpu(x)\n",
    "z = cpu(y)\n",
    "w = cpu(x)\n",
    "\n",
    "print(gpu.name())\n",
    "print('x is not on cuda', x.is_cuda)\n",
    "print('y is on cuda (if possible)', y.is_cuda)\n",
    "print('z is taken from y, z is not on cuda', z.is_cuda)\n",
    "print('w is taken from x, w is not on cuda', w.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MNIST dataset\n",
    "\n",
    "For single channel images, don't forget the trailing commas as seen below.\n",
    "\n",
    "`transforms.Normalize((0.5,),(0.5,))`\n",
    "\n",
    "We normalize the MNIST images in this manner to ensure that pixel values lie between -0.5 and 0.5.  This allows us to use a sigmoid when predicting pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = MNIST('../datasets', transform=my_transforms, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'idx = 41149, Label = 6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Size of dataset: ', len(dataset))\n",
    "idx = np.random.choice(len(dataset))\n",
    "x, y = dataset[idx]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x.squeeze())\n",
    "plt.title('idx = {}, Label = {}'.format(idx,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method `to_img` is the opposite of what `Normalize` above does to an MNIST image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make an autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, 12), \n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(12, 3))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(128, 28 * 28), # arbitrary values\n",
    "            nn.Tanh())               # squished between -1 and 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = cudafy()\n",
    "\n",
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-5\n",
    "\n",
    "model = gpu(autoencoder())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.1609\n",
      "epoch [2/100], loss:0.1489\n",
      "epoch [3/100], loss:0.1413\n",
      "epoch [4/100], loss:0.1394\n",
      "epoch [5/100], loss:0.1502\n",
      "epoch [6/100], loss:0.1591\n",
      "epoch [7/100], loss:0.1477\n",
      "epoch [8/100], loss:0.1468\n",
      "epoch [9/100], loss:0.1468\n",
      "epoch [10/100], loss:0.1427\n",
      "epoch [11/100], loss:0.1354\n",
      "epoch [12/100], loss:0.1366\n",
      "epoch [13/100], loss:0.1446\n",
      "epoch [14/100], loss:0.1442\n",
      "epoch [15/100], loss:0.1328\n",
      "epoch [16/100], loss:0.1427\n",
      "epoch [17/100], loss:0.1389\n",
      "epoch [18/100], loss:0.1430\n",
      "epoch [19/100], loss:0.1432\n",
      "epoch [20/100], loss:0.1418\n",
      "epoch [21/100], loss:0.1250\n",
      "epoch [22/100], loss:0.1256\n",
      "epoch [23/100], loss:0.1493\n",
      "epoch [24/100], loss:0.1316\n",
      "epoch [25/100], loss:0.1476\n",
      "epoch [26/100], loss:0.1462\n",
      "epoch [27/100], loss:0.1292\n",
      "epoch [28/100], loss:0.1342\n",
      "epoch [29/100], loss:0.1408\n",
      "epoch [30/100], loss:0.1453\n",
      "epoch [31/100], loss:0.1324\n",
      "epoch [32/100], loss:0.1370\n",
      "epoch [33/100], loss:0.1381\n",
      "epoch [34/100], loss:0.1420\n",
      "epoch [35/100], loss:0.1443\n",
      "epoch [36/100], loss:0.1282\n",
      "epoch [37/100], loss:0.1424\n",
      "epoch [38/100], loss:0.1432\n",
      "epoch [39/100], loss:0.1360\n",
      "epoch [40/100], loss:0.1578\n",
      "epoch [41/100], loss:0.1356\n",
      "epoch [42/100], loss:0.1410\n",
      "epoch [43/100], loss:0.1376\n",
      "epoch [44/100], loss:0.1445\n",
      "epoch [45/100], loss:0.1247\n",
      "epoch [46/100], loss:0.1410\n",
      "epoch [47/100], loss:0.1416\n",
      "epoch [48/100], loss:0.1342\n",
      "epoch [49/100], loss:0.1378\n",
      "epoch [50/100], loss:0.1339\n",
      "epoch [51/100], loss:0.1294\n",
      "epoch [52/100], loss:0.1529\n",
      "epoch [53/100], loss:0.1358\n",
      "epoch [54/100], loss:0.1596\n",
      "epoch [55/100], loss:0.1541\n",
      "epoch [56/100], loss:0.1388\n",
      "epoch [57/100], loss:0.1357\n",
      "epoch [58/100], loss:0.1441\n",
      "epoch [59/100], loss:0.1342\n",
      "epoch [60/100], loss:0.1481\n",
      "epoch [61/100], loss:0.1393\n",
      "epoch [62/100], loss:0.1344\n",
      "epoch [63/100], loss:0.1425\n",
      "epoch [64/100], loss:0.1379\n",
      "epoch [65/100], loss:0.1320\n",
      "epoch [66/100], loss:0.1498\n",
      "epoch [67/100], loss:0.1322\n",
      "epoch [68/100], loss:0.1480\n",
      "epoch [69/100], loss:0.1540\n",
      "epoch [70/100], loss:0.1432\n",
      "epoch [71/100], loss:0.1365\n",
      "epoch [72/100], loss:0.1374\n",
      "epoch [73/100], loss:0.1422\n",
      "epoch [74/100], loss:0.1415\n",
      "epoch [75/100], loss:0.1471\n",
      "epoch [76/100], loss:0.1339\n",
      "epoch [77/100], loss:0.1427\n",
      "epoch [78/100], loss:0.1389\n",
      "epoch [79/100], loss:0.1313\n",
      "epoch [80/100], loss:0.1367\n",
      "epoch [81/100], loss:0.1423\n",
      "epoch [82/100], loss:0.1399\n",
      "epoch [83/100], loss:0.1483\n",
      "epoch [84/100], loss:0.1344\n",
      "epoch [85/100], loss:0.1324\n",
      "epoch [86/100], loss:0.1412\n",
      "epoch [87/100], loss:0.1437\n",
      "epoch [88/100], loss:0.1547\n",
      "epoch [89/100], loss:0.1338\n",
      "epoch [90/100], loss:0.1372\n",
      "epoch [91/100], loss:0.1528\n",
      "epoch [92/100], loss:0.1431\n",
      "epoch [93/100], loss:0.1355\n",
      "epoch [94/100], loss:0.1319\n",
      "epoch [95/100], loss:0.1306\n",
      "epoch [96/100], loss:0.1529\n",
      "epoch [97/100], loss:0.1454\n",
      "epoch [98/100], loss:0.1514\n",
      "epoch [99/100], loss:0.1515\n",
      "epoch [100/100], loss:0.1425\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for data in dataloader:        \n",
    "        img, _ = data # img is a [batch_size, num_channels, 28, 28] tensor\n",
    "                      # here num_channels is 1\n",
    "            \n",
    "        img = img.view(img.size(0), -1) # We resize it to [batchsize, 1x28x28] tensor\n",
    "        img = gpu(Variable(img))\n",
    "\n",
    "        output = model(img) # Forward\n",
    "        loss = criterion(output, img)\n",
    "\n",
    "        optimizer.zero_grad() # Backward & update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, 'image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model\n",
    "\n",
    "Now that training is done, it is a good idea to save the trained model.\n",
    "\n",
    "We are interested in state_dict dictionary that contains parameters associated with each layer in the model.  Optimizer too has a state_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "encoder.0.weight  --  torch.Size([128, 784])\n",
      "encoder.0.bias  --  torch.Size([128])\n",
      "encoder.2.weight  --  torch.Size([64, 128])\n",
      "encoder.2.bias  --  torch.Size([64])\n",
      "encoder.4.weight  --  torch.Size([12, 64])\n",
      "encoder.4.bias  --  torch.Size([12])\n",
      "encoder.6.weight  --  torch.Size([3, 12])\n",
      "encoder.6.bias  --  torch.Size([3])\n",
      "decoder.0.weight  --  torch.Size([12, 3])\n",
      "decoder.0.bias  --  torch.Size([12])\n",
      "decoder.2.weight  --  torch.Size([64, 12])\n",
      "decoder.2.bias  --  torch.Size([64])\n",
      "decoder.4.weight  --  torch.Size([128, 64])\n",
      "decoder.4.bias  --  torch.Size([128])\n",
      "decoder.6.weight  --  torch.Size([784, 128])\n",
      "decoder.6.bias  --  torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \" -- \" , model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state\n",
      "param_groups\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name)\n",
    "    #print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch preferred approach to save the model is to use model's state_dict.\n",
    "\n",
    "We have commented it out, so we don't overwrite the file mistakenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'simple-ae-weights-100.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now lets pass an image through the learned model and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'idx = 0, Label = 0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[1]\n",
    "print(image.shape, label)\n",
    "\n",
    "idx = 0\n",
    "plt.figure()\n",
    "plt.imshow(image[idx])\n",
    "plt.title('idx = {}, Label = {}'.format(idx, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now pass this image through the network and see what we get.  We will have to \"normalize\" and \"de-normalize\" the data as needed.  We also use `unsqueeze_()` to create a batch of size 1.  Recall that our model expects data to be in the form: batch x ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d038e2ce8bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch x (28 x 28) = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "ni = image\n",
    "ni.unsqueeze_(0)\n",
    "ni = ni.view(1, -1)\n",
    "print('batch x (28 x 28) = ', ni.shape)\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    ni = Variable(ni).cuda() # Lets put this on Cuda\n",
    "#else:\n",
    "#    ni = Variable(ni)\n",
    "\n",
    "\n",
    "oi = model(gpu(ni))\n",
    "#print(oi.shape)\n",
    "oi_ = to_img(oi)\n",
    "#print(oi_.shape)\n",
    "\n",
    "plt.imshow(cpu(oi_[0,0,:,:].detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved model\n",
    "\n",
    "We can easily load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = cudafy()\n",
    "model2 = gpu(autoencoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following should produce garbage, since we haven't trained the model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f19a0bfc198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG8hJREFUeJztnXt0nWWZ9q87O6cmadKmbZr0XKBASymlpBUsMlWwclIOI3yiC6ui5RNxUFyuD5nlwPg5Sz9nQJkZhvVVQVvFinISkSoHDwgUaQqxLfRc0rQ0TdOmzblJk9zzRzeuAH2uHZJ07zjP9VurqzvvtZ/3ffa797Xfvff93Pdt7g4hRHxkZXoCQojMIPMLESkyvxCRIvMLESkyvxCRIvMLESkyvxCRIvMLESkyvxCRkp3Og+XkFnp+weig7pZiB+O6w/vO6qFD2zvy+L5THDw7P3zsnlZ+Gq2Az60ot5PqLc0FfP9k91YUnjcAZB3gcz9SzFeAZrfw89ZdSI6dy89LXjafe2+K58x2Er2nl47tHsVfL1mlR/j4Hn5d9fZEUMsp4vvuacoJal3NjejuaEvlJACDNL+ZXQjgLgAJAD9w92+z++cXjMbc824K6h4+H0e5oSEolRc206Fr1p1Idevm56vspANBrenFMjo264wmqp87eQfVf//0XKrnNofnnrdwPx07Ynn4zRgA3vgQN0n57/mTVn92+M1j5BT+nE0dfZDqXT382FnXEwMfaqFjGz58EtWLP/4G1fc2jaR677qSoDZ+4R46tumxCUFt6wN30rF9GfDHfjNLALgbwEUAZgG4xsxmDXR/Qoj0Mpjv/AsAbHP3He7eBeBnAC4bmmkJIY43gzH/RAC7+vy9O7ntLZjZUjOrMrOqI11tgzicEGIoGYz5j/VF8x1f8Nx9mbtXuntlTi759UcIkVYGY/7dACb3+XsSAP5LhRBi2DAY868BMMPMpptZLoCPAXhsaKYlhDjeDDjU5+7dZnYjgN/iaKjvPnd/lY4p60bPjeHQU8fD4+kxRyXCceHND51CxxbmUhl4Dw/HHWwJx9qLd/FY+P7p+VS/aPR6qtcvLKb69sfDYczclaV07N6zqYxFp2+i+u7lPIQ66x+2BbWaVj63tm+84yekt5DVydcJ7LujI6i1buChPLZ2AgCyVvC53fS1X1L9P7IWBbU9B8JhQADII8s+/F1czgcV53f3JwA8MZh9CCEyg5b3ChEpMr8QkSLzCxEpMr8QkSLzCxEpMr8QkZLWfP7ephy0/ro8qM/59AY6fscdM4Na6fU8xdL+31iqH2rmsfSesnDa7IFKHhTObuCLDG5ZeS3VOyfw/O4SUg4gv5HPrXBXODccAN4/aiPVv3nJbKpn/cP0oFZ7ZREfu4jKKJjDU36zs8LrL6Y93k7HVt79CtV/vfM0qt+x7gKqTygNryvZW83XELSe2hXUevP734FLV34hIkXmFyJSZH4hIkXmFyJSZH4hIkXmFyJSzL3/oYHBUjpznC++74qg/pdfh0N5AHDPZ/8rqC35w2fp2HHjecruVVNfpvrP/n1xUGucz0tMF43l5cumfIWHnbb87wqqF+4KhyGLLtlLxx65n6dRJ7r466PkCZrFjX0/Dc99ZF44ZAUAZ42ppfqq13m92K7XwxV0x1bzx9V0Er8uTl9ZT/Ut14+j+tiZ4dT2tj/watA/+vz3gtonP7wXG9d19qt0t678QkSKzC9EpMj8QkSKzC9EpMj8QkSKzC9EpMj8QkRKWuP8k2aX+Bd/fk5Qf6j2TDo+d1m41POIL/J+IbufnkL1rAWHqN770qigZvP5GoKSlTx1dc+FPO22YBtPCW6fGl5nMHoCn1tH1RiqFy3gXX7tF3x8blu4y2/HGH7tOTibdwj2FO3HZ/wgfF4bZ46gY5sv4GszLjuZl1ufktdI9f967bygZtW8w++4v4Qfd/Wzd6Hl0G7F+YUQYWR+ISJF5hciUmR+ISJF5hciUmR+ISJF5hciUgYV5zezGgAtAHoAdLt7Jbt/3tRJXv6PNwX14vIWerwvn/pMUPvm2kvo2JGreVy3c1Ez1RMvhUt7j6hPkfP+yd1UH5lzmOpnlPCy5GsOTg1qvc5DvptenUz1RBu/PhTvoDIazwrHpE8/ZRcdu+OJE/jOU9A+K3xepy/n56VpOl9bcXgsHz++itRTB9AxNlwyvTuf77txcfhxvfGPd6Nzxxv9ivMPRd3+97s7XwkihBh26GO/EJEyWPM7gCfNbK2ZLR2KCQkh0sNgP/YvdPc9ZlYG4Ckz2+Tuz/a9Q/JNYSkAJErD6+OFEOllUFd+d9+T/H8fgEcALDjGfZa5e6W7VyaKCgdzOCHEEDJg85tZoZmNfPM2gMUAeKdNIcSwYTAf+8cDeMTM3tzPT939N0MyKyHEcWfA5nf3HQDOeFcHazOUvZAI6rNv4HHf72wI185PZPOc+KxU9ecf5jn3++eExxft4vvevnEC1bNb+Aew6ok8Fj9+HGn3XDeaji3aGX4+AKCrspXqh5v4eSvZEI5nbx/DawF0F/HzmkhRnn7qyvBjy/s6XzvRtp/PrXcLf9y7PsjXCRjpuj7tvdwHnY+Fa1NkpViX8Zb79vueQoj/Ucj8QkSKzC9EpMj8QkSKzC9EpMj8QkTKUGT19ZvuAmD/meHwTXUDD4l1NBQEtZmn8rTZfc5XF5b+iY9vKw+HVxou5Sm5hQU8vXNELon7AGio5eG6Q9vCbbZLeEVydIaroQMAug7mU/09H+brul7cOS2o5T9fQseW1vDwbcdofu1qmRR+ebf8JJwGDQD5I3gY8WPXP0X1x2/7ANV9aUNQa//PiXRsz7WkHPuv+Dnri678QkSKzC9EpMj8QkSKzC9EpMj8QkSKzC9EpMj8QkRKWuP81gPkNoXfbw6/MJaOX3zFK0HtyXWn0bH//JVfUP322R+lesXz4XbRE55NEac/i8ezsy4Lx3wB4KST66je8XR4fUTLZJ6ya7zLNT5x9mqq13bwNQjYEV5f0V7ZTodmt/Ny68U7+eTrPhVeX5FdzVNyz75sHdV/++Vwi20AODyZX1ebXg6vzeg5j6cyT1wRPqe1B5TSK4RIgcwvRKTI/EJEiswvRKTI/EJEiswvRKTI/EJESlrj/FlHgIK6cAwzwdPesfP6cMvmUefwUsl3rbmK6iUXH6R699pwPLvzW7y1uD88kuoH146jev5qHs8+7fZwTPqp12bRsTO/xktYP9r9PqrnHUzR4n16WOpp5s9Zfop9117I1zDMm7AnqO16fAYdW7eknOoNH8mj+oR/fYHq++95R3Orv5KqLXrOjXuDmr2aYuFGH3TlFyJSZH4hIkXmFyJSZH4hIkXmFyJSZH4hIkXmFyJSUsb5zew+AJcC2Ofus5PbSgE8AGAagBoAV7s7D5QD8ARweEy4Hnp3AY/r+kfDefMjfhzOtwcA8DLsmFC6n+rVZ4wKal2P8Drr49c0U73hti6q147iOfOH7wp3Sp+xnefM13wqvHYCAMrP5/0MWn7CH3t2W/jEZ3XxOH03T+fH2HB5BwBAdVc4ll9Yyl8QG78afr4B4KxTtvDxOe+luhWGez2cOpPXb6hZFV480d0cbon+dvpz5f8RgAvftu0WAM+4+wwAzyT/FkL8DZHS/O7+LIDGt22+DMDy5O3lAC4f4nkJIY4zA/3OP97d6wAg+X/Z0E1JCJEOjvsPfma21MyqzKyqu73teB9OCNFPBmr+ejOrAIDk//tCd3T3Ze5e6e6V2QW8WaYQIn0M1PyPAViSvL0EwC+HZjpCiHSR0vxmthLAagCnmNluM7sOwLcBfNDMtgL4YPJvIcTfECnj/O5+TUA6/90erDcH6KgI9w8vquFx3zljw/nZf6wcQ8dmd/C5tR3gOfXFM8LLGA6N5V9n2it4Pn/Jg1RG1uJwTBgAzr55fVD78z7eh370D3gw3dfw89LMy9fj5L/bEdRmF4efTwBYuTac8w4AV59VRfXHfx6Otc/4KI/Tb03xenhl52Sq+6n8ORs9ujWonVbC4/z17wu/nrIeVD6/ECIFMr8QkSLzCxEpMr8QkSLzCxEpMr8QkZLW0t0wh+eE03YLL6inw1c/Pieozf0QD928/PJJVF9xxgqqX3fPTUEtq4ynE0/+Ha9Jnn8bD+0cqObhuid2zQ9qxruHI/vjPN0493e8vXgiRQg1PxGewK938rbqEye9PZ/srTz/zfdQPXtKWNvUEG6RDQAlK3kLb/8EP28TrtpO9axR4fP64HfPpGOLXwyHZ725/5bWlV+ISJH5hYgUmV+ISJH5hYgUmV+ISJH5hYgUmV+ISElvnL/XkGgJp+12PcpLAU77WE1Qe2Utj+PntPBSzSv2n0v1r3/2/qB2y+q/p2MPzMynesueFDHnzXzun7xxVVBbsZ3Hwo/08DTq7HZeTv27N/9/qt/yT0vDYhm/9nTv4+sn2qbz8e2TwuMTm4vp2OfvuofqZ37zBqp/ddNaqt9Q9YmglrMpRZr1EF2ydeUXIlJkfiEiReYXIlJkfiEiReYXIlJkfiEiReYXIlLSG+fP6YVNDCeANxbl0uGNOyYEtYJ6/j42dXEN1VdtnkX1vVPD5ZITdXl07KHTeTnlGXdTGfXzeZz/wV3zgtqFkzfSsau+z9c3JLp4rH1LVznVO0eFn5dO3gUbrfN4HYTTpvA6CF1fCpdz33ITX3uxaAPvPds+ka9/uOPiK6he+IFwufe2ReGy3gBwpDpca+DdrAHQlV+ISJH5hYgUmV+ISJH5hYgUmV+ISJH5hYgUmV+ISEkZ5zez+wBcCmCfu89ObrsdwOcANCTvdqu7P5HyaF1ZQG04V3ny6nD7bgCor8wJan4Wr6Pe3MnjulNX8Lz27V8YG9SKX6dD0V6R4jQ7j2f38GUEaHw+HGv/RRGvFXD5Z1dT/akfnkP1+796KdXzSsLrBFqm06HwXr6+4fCtfI3BzlvCx7a68GsJAHor+LF7p/OGBTX/wl9vxY+G1wkcbOdzm7i2K6jtTlF/oS/9ufL/CMCFx9j+XXefm/yX2vhCiGFFSvO7+7MAeOsUIcTfHIP5zn+jma0zs/vMbPSQzUgIkRYGav57AJwIYC6AOgB3hO5oZkvNrMrMqnrb2gZ4OCHEUDMg87t7vbv3uHsvgO8DWEDuu8zdK929MqswnMwghEgvAzK/mVX0+fMKABuGZjpCiHTRn1DfSgCLAIw1s90AbgOwyMzmAnAANQCuP45zFEIcB1Ka392vOcbmewdyMHMgi/SL33Uxj1GOn9wQ1HITfI1AV4r69Hs+zo/9/vG7g9rqsaV0bDZPz8a2pfxpyDrAc+p7CsN6/hgej97awnsl5Dbz87Kvks/9cFm4lsEH5r1Gxx7o5F8T879DXkwAtq85OaidckYtHbv7V9OoPm0NP6/ZTbyGw5bPhLWCLXxhx975Ye3IOr4+oS9a4SdEpMj8QkSKzC9EpMj8QkSKzC9EpMj8QkRKWkt3JzqBUVvDeuGfeFjp9cvDIbWiHfyhXPdpnnj4k0cuovqaUZODWt4CnvfU3MJbLmfX8vTPIxXhFE4AyK4PlzzP3xAuOQ4A6xbw9NERE1Kk1ZbzkFb5s+HrS82Dp9CxzdN4Kff983l4N1F2OKjV/mYaHTtmC39c3YX89daby8OUuQfD5yUnxSr485e8GNR++lD/l9Dryi9EpMj8QkSKzC9EpMj8QkSKzC9EpMj8QkSKzC9EpKQ1zp8zthPjrwvXua557AQ6Prs1vA7gCA9n4zefeh/f9z+H04UBoOvpcOproomvTygq5rHyL1//INXv/Rpv9+xZ4ZTe+vn8/T2nlqePJnhVcUyYtp/qba+Gy2vvfT+fW9mf+LGLN/GX78yrtwW1XaW8P3j+H8NtsAFgy2f4ebMOvn7i1Dk1Qa32t9Po2PVfPD2oddQ+R8f2RVd+ISJF5hciUmR+ISJF5hciUmR+ISJF5hciUmR+ISIlrXH+nt4s2iq7dSrPzx5THX6v6vrIQTp2x8k8NzzxEi9h3TknHPAeP/4QHcsjvsDGjgn8DimqMbdMDpcl76kI57QDwLmnkAILAP7wGs+5H3nvOKp3X9MU1Gw3j6W3fKSF6h2HeB2EK8etDWrfuv8TdOyeT/Oy4KPLeUv4rF/xcu52J3nO/o0/7u3jw7UCOmv7fz3XlV+ISJH5hYgUmV+ISJH5hYgUmV+ISJH5hYgUmV+ISEkZ5zezyQBWACgH0AtgmbvfZWalAB4AMA1ADYCr3Z0G27s6c1C7ZXxQzz3I22jvX0jq19fxhP7izSnqrKc4E7l/Cedvt3v4MQHAEV7CHZsX8x7ede/lgf4pT4bPS94hnnf+x6ZZVB93Iu9JkLuU9xQovrciqCXK+bWno4zrN5/zFNV/2xjOe285kbc9zy/l6yOOPDeG6q1n8rr/zdMnBbXsav5855KFI8aXyryF/lz5uwF8xd1nAjgbwBfMbBaAWwA84+4zADyT/FsI8TdCSvO7e527v5y83QJgI4CJAC4DsDx5t+UALj9ekxRCDD3v6ju/mU0DcCaAPwMY7+51wNE3CAB8fawQYljRb/ObWRGAhwB8yd35wua3jltqZlVmVtXTyr/bCiHSR7/Mb2Y5OGr8+9394eTmejOrSOoVAPYda6y7L3P3SnevTBTxRA4hRPpIaX4zMwD3Atjo7nf2kR4DsCR5ewmAXw799IQQx4v+pPQuBHAtgPVmVp3cdiuAbwP4uZldB6AWwFUpD5bXjbITDgT1rg08PbSTtIuesYLXmG4+kb/PNV/Ov5J0dIbjK2N+w1NLW+bxua17PRz2AYCKP/PS4HWfC+9/Umk9HduxKtx6HAAO9PCQ1qhfdFD98NSw1v2+cLovAPR08DTs7Yf566Xu2vDPUL1f5yHKEXlcL32JhwK75/OU4LJV4bbtDXO5LcuqwmHEPW38tdKXlOZ39+cQzig/v99HEkIMK7TCT4hIkfmFiBSZX4hIkfmFiBSZX4hIkfmFiJS0lu52B470hN9vsnhoFDkN4el2VPD3sdZJXM9+oZjrRMvq4emhOXk8vTPnFb7y0RN8/+U/CKftTvsGT8nNuYTngG7aGU7JBYD69/B85fbycNy54sd8bMtE/vKseuQsqvdUhteFZNXztNkTptdSffek0VSfPnYv1bdeE16DcOaU7XTsrm0zglpvIkWd9z7oyi9EpMj8QkSKzC9EpMj8QkSKzC9EpMj8QkSKzC9EpKQ1zp9oSGDkPSVBff/pPEY5aks4ZuxLG+jYsjt5y+QDM3nueBYJ1TdP5e+hpcVtVO99g8e7R7/EY8abbygPak31vFZA0w4er85p5c9J3gX8vHc0FwS1XcW8rPi4FHUMDo/m593I8oiytXzfr28Nx9IBoOVS/px2/4QUMgDQc164BsMrz53Mx14UHtu9uv/5/LryCxEpMr8QkSLzCxEpMr8QkSLzCxEpMr8QkSLzCxEpaY3zdxUbaj8UbsNdtobnrSdIKfXuXv4+tu8DpK8xgO6RPK+9eFN43s47i+PQi7yFd88lvGdA6bpwjXcAGLEv/NgPjeNrCLyEF1E4UsrjxldNfZnqD3xvcVA7OIvvu+EcXgchl9R3AICe/PD+S7bw9QtdJVwvKuC9GDou5q8nrw8/Lz0VfN/nztgW1Fbl8X4CfdGVX4hIkfmFiBSZX4hIkfmFiBSZX4hIkfmFiBSZX4hISRnnN7PJAFYAKAfQC2CZu99lZrcD+ByANxO6b3X3J+jB8rtRNmN/UD9UwePZ3bvCsVE/MJKO9RSx0ykP8GD9oZPCetE5PKe98bWxVM9yHlN+/Uqec19cGT5+90u8h335i7wP/b55POf+x8ULqP6hG14Mas8sO5uO9QRfmzH9f22len4ivE6getpEOrZ0JV8f0Zg3huodE/kaBSsM69l1/Jw/n3ViUGvt5GPfcpx+3KcbwFfc/WUzGwlgrZk9ldS+6+7/1u+jCSGGDSnN7+51AOqSt1vMbCMA/rYphBj2vKvv/GY2DcCZAP6c3HSjma0zs/vM7JifTc1sqZlVmVlVd1P7oCYrhBg6+m1+MysC8BCAL7l7M4B7AJwIYC6OfjK441jj3H2Zu1e6e2V2SbiemxAivfTL/GaWg6PGv9/dHwYAd6939x537wXwfQD8lx8hxLAipfnNzADcC2Cju9/ZZ3vf9q1XANgw9NMTQhwv+vNr/0IA1wJYb2bVyW23ArjGzOYCcAA1AK5PtaPeXkN7Vzh8k5PD0yAT+8PvVZ3OQxyJbh5Oa1x6iOoly8MtvAv+Lw9RHryCyjjxWzwMuflm/jQ1NoXDUnlzmujY8/9+LdV/+PQiqo95ZBTVHz0tHM6zRbz8dWITb12+9XFeXrvyyvVBreMgf87ay/h18ZIrV1P9oRf4B+Giko6g1tbIy8gXvhKee1Z7/3/G68+v/c8BOJZzaExfCDG80Qo/ISJF5hciUmR+ISJF5hciUmR+ISJF5hciUsy9/y19B8uIisk+7TM3B/W/u5KXgX71G3OCWt3Heaz8whmvUX3V05VULzg1vA6gq5qn3I6Yd4DqZ43fTfXfvXA61e/+8A+D2ud/90k6duRmnjbbu5CvE2hvSZFCeigcsx5TzddezPt8NdWr/3Mu1RsuCL8myp7ksXRWJh4A8g7xlN2981Psn1RMz2/gnsxtC+vrn/weWht38RObRFd+ISJF5hciUmR+ISJF5hciUmR+ISJF5hciUmR+ISIlrXF+M2sAsLPPprEAwrW8M8twndtwnReguQ2UoZzbVHfn9dqTpNX87zi4WZW789U1GWK4zm24zgvQ3AZKpuamj/1CRIrML0SkZNr8yzJ8fMZwndtwnReguQ2UjMwto9/5hRCZI9NXfiFEhsiI+c3sQjPbbGbbzOyWTMwhhJnVmNl6M6s2s6oMz+U+M9tnZhv6bCs1s6fMbGvyf55PnN653W5mbyTPXbWZXZyhuU02s9+b2UYze9XMbkpuz+i5I/PKyHlL+8d+M0sA2ALggwB2A1gD4Bp35wn3acLMagBUunvGY8Jmdh6AVgAr3H12ctt3ADS6+7eTb5yj3f3/DJO53Q6gNdOdm5MNZSr6dpYGcDmATyGD547M62pk4Lxl4sq/AMA2d9/h7l0AfgbgsgzMY9jj7s8CaHzb5ssALE/eXo6jL560E5jbsMDd69z95eTtFgBvdpbO6Lkj88oImTD/RAC7+vy9G8Or5bcDeNLM1prZ0kxP5hiMT7ZNf7N9elmG5/N2UnZuTidv6yw9bM7dQDpeDzWZMP+xSgwNp5DDQnefB+AiAF9IfrwV/aNfnZvTxTE6Sw8LBtrxeqjJhPl3A5jc5+9JAPZkYB7HxN33JP/fB+ARDL/uw/VvNklN/r8vw/P5K8Opc/OxOktjGJy74dTxOhPmXwNghplNN7NcAB8D8FgG5vEOzKww+UMMzKwQwGIMv+7DjwFYkry9BMAvMziXtzBcOjeHOksjw+duuHW8zsgin2Qo43sAEgDuc/d/SfskjoGZnYCjV3vgaBPTn2Zybma2EsAiHM36qgdwG4BHAfwcwBQAtQCucve0//AWmNsiHP3o+tfOzW9+x07z3M4F8CcA6wH0JjffiqPfrzN27si8rkEGzptW+AkRKVrhJ0SkyPxCRIrML0SkyPxCRIrML0SkyPxCRIrML0SkyPxCRMp/A+hM+WEUE5uFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oi = model2(gpu(ni))\n",
    "oi_ = to_img(oi)\n",
    "plt.imshow(cpu(oi_[0,0,:,:].detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load the model and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('simple-ae-weights.pt', map_location='cpu'))\n",
    "oi = model2(gpu(ni))\n",
    "oi_ = to_img(oi)\n",
    "plt.imshow(cputoi_[0,0,:,:].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when you load the model all is well in the world of autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using part of the trained network\n",
    "\n",
    "Now lets assume we are interested in the **encoder** stage only.  I.e., we want to pass an MNIST image and wants to get its 3-dimensional encoding.  We can do it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_encoder, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(*list(model2.encoder.children())[:])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = gpu(my_encoder())\n",
    "encoding = encoder(gpu(ni))\n",
    "print(encoding.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we only care about the **decoder** stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_decoder, self).__init__()\n",
    "        \n",
    "        self.reconstruction = nn.Sequential(*list(model2.decoder.children())[:])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.reconstruction(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.empty((1,3))\n",
    "v[0,0] = 0.01\n",
    "v[0,1] = 0.0001\n",
    "v[0,2] = 1\n",
    "print(v)\n",
    "\n",
    "d = my_decoder()\n",
    "ooi = d(gpu(v))\n",
    "print(ooi.shape)\n",
    "ooi_ = to_img(ooi)\n",
    "plt.imshow(ooi_[0,0,:,:].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
